{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e33b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn.functional import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import torch.utils.data as D\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf3c13",
   "metadata": {},
   "source": [
    "## Dataset preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33f35cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:\t torch.Size([2592000, 4])\n",
      "Input shape:\t torch.Size([2591990, 40])\n",
      "Output shape:\t torch.Size([2591990, 4])\n"
     ]
    }
   ],
   "source": [
    "dataset = t.load(\"data/ffa_channelpark.pt\", weights_only=False)\n",
    "observations,_ = dataset.tensors\n",
    "positions = observations[:,:3].float()\n",
    "\n",
    "angles =  10 * positions[:, 2] * t.pi / 180\n",
    "cosi = t.stack([t.cos(angles), t.sin(angles)], dim=1)\n",
    "positions = t.cat((positions[:, :2], cosi,positions[:,3:]), dim=1)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#positions_scaled = t.tensor(scaler.fit_transform(positions))\n",
    "positions_scaled = normalize(positions,dim=0)\n",
    "\n",
    "X = positions[:-1].unfold(dimension=0, size=10, step=1).flatten(start_dim=1,end_dim=2)\n",
    "y =  positions[10:]  \n",
    "\n",
    "X_scaled = positions_scaled[:-1].unfold(dimension=0, size=10, step=1).flatten(start_dim=1,end_dim=2)\n",
    "y_scaled =  positions_scaled[10:]  \n",
    "\n",
    "print(\"Data shape:\\t\",positions.shape)\n",
    "print(\"Input shape:\\t\",X.shape)\n",
    "print(\"Output shape:\\t\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f54b4f",
   "metadata": {},
   "source": [
    "## Constant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87d9920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:\t 0.00035304092751520277\n"
     ]
    }
   ],
   "source": [
    "mse  = mean_squared_error(positions[1:], positions[:-1])\n",
    "print(\"Mean squared error:\\t\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b372ce2",
   "metadata": {},
   "source": [
    "##  Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bca07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:\t 0.0017755660228431225\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X, y)\n",
    "y_pred = reg.predict(X)\n",
    "mse  = mean_squared_error(y, y_pred)\n",
    "print(\"Mean squared error:\\t\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81faac9c",
   "metadata": {},
   "source": [
    "## Multioutput Regression using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4164888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:\t 0.0003713804898648525\n"
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(SGDRegressor(loss=\"squared_error\",tol=1e-3)).fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "mse  = mean_squared_error(y, y_pred)\n",
    "print(\"Mean squared error:\\t\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e5724",
   "metadata": {},
   "source": [
    "### Again but with Max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ce63153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:\t 0.0217948220161012\n"
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(SGDRegressor(loss=\"squared_error\",tol=1e-3)).fit(X_scaled, y)\n",
    "y_pred = model.predict(X_scaled)\n",
    "mse  = mean_squared_error(y, y_pred)\n",
    "print(\"Mean squared error:\\t\",mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f94ae9",
   "metadata": {},
   "source": [
    "## Torch's linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb886b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss for iteration 0:\t0.7120311856269836\n",
      "Train loss for iteration 200:\t0.05224146693944931\n",
      "Train loss for iteration 400:\t0.027928924188017845\n",
      "Train loss for iteration 600:\t0.025338636711239815\n",
      "Train loss for iteration 800:\t0.023620178923010826\n",
      "Train loss for iteration 1000:\t0.022054994478821754\n"
     ]
    }
   ],
   "source": [
    "model = t.nn.Linear(40, 4).to(t.float32)\n",
    "opt = t.optim.SGD(lr=1e-3, params=model.parameters())\n",
    "loss_fn = t.nn.MSELoss()\n",
    "for i in range(1001):\n",
    "     train_loss = loss_fn(y, model(X))\n",
    "     if i%200==0:\n",
    "          print(f'Train loss for iteration {i}:\\t{train_loss}')\n",
    "     opt.zero_grad()\n",
    "     train_loss.backward()\n",
    "     opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261eab65",
   "metadata": {},
   "source": [
    "### Again but with Max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e1b4fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss for iteration 0:\t0.5132244229316711\n",
      "Train loss for iteration 200:\t0.4241345524787903\n",
      "Train loss for iteration 400:\t0.3511976897716522\n",
      "Train loss for iteration 600:\t0.2914852201938629\n",
      "Train loss for iteration 800:\t0.24259929358959198\n",
      "Train loss for iteration 1000:\t0.20257702469825745\n"
     ]
    }
   ],
   "source": [
    "model = t.nn.Linear(40, 4).to(t.float32)\n",
    "opt = t.optim.SGD(lr=1e-3, params=model.parameters())\n",
    "loss_fn = t.nn.MSELoss()\n",
    "for i in range(1001):\n",
    "     train_loss = loss_fn(y, model(X_scaled))\n",
    "     if i%200==0:\n",
    "          print(f'Train loss for iteration {i}:\\t{train_loss}')\n",
    "     opt.zero_grad()\n",
    "     train_loss.backward()\n",
    "     opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff2e39",
   "metadata": {},
   "source": [
    "### Again but using batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fea33cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss for epoch 0:\t0.003784812055528164\n",
      "Train loss for epoch 1:\t0.0018951307283714414\n",
      "Train loss for epoch 2:\t0.001179864164441824\n",
      "Train loss for epoch 3:\t0.0008855920750647783\n",
      "Train loss for epoch 4:\t0.0007515850011259317\n",
      "Train loss for epoch 5:\t0.0006834083469584584\n",
      "Train loss for epoch 6:\t0.0006446100305765867\n",
      "Train loss for epoch 7:\t0.0006199977942742407\n",
      "Train loss for epoch 8:\t0.0006027251947671175\n",
      "Train loss for epoch 9:\t0.0005894865025766194\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "train_loader = D.DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "model = t.nn.Linear(40, 4).to(t.float32)\n",
    "opt = t.optim.SGD(lr=1e-3, params=model.parameters())\n",
    "loss_fn = t.nn.MSELoss()\n",
    "for j in range(10):\n",
    "     for i, (b_x, b_y) in enumerate(train_loader):\n",
    "          train_loss = loss_fn(b_y, model(b_x))\n",
    "          opt.zero_grad()\n",
    "          train_loss.backward()\n",
    "          opt.step()\n",
    "     print(f'Train loss for epoch {j}:\\t{train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba97b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altitude_rl",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
